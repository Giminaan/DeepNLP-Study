<a>https://arxiv.org/abs/1506.05869</a>

* Ybigta 10기 김우정

**seq2seq 모델로 end-to-end 챗봇을 만들자**

# 1. Introduction

* end-to-end training of neural network in many domains - speech recognition, computer vision, language processing
* seq2seq model (Sutskever et al., 2014)
   * 적은 feature engineering 필요
   * 적은 domain knowledge 필요
* conversation modeling - feature engineering needed , domain-specific
* 두가지 dataset에 대해 실험
   * IT helpdesk dataset
   * 영화 자막
* n-gram 모델과 비교

# 2. Model

**seq2seq model**

* input sequence를 한 타임 스텝에 한 토큰씩 받아서 output sequence를 한 토큰씩 내보냄

* input sequence를 multilayered LSTM을 통하여 고정된 크기의 벡터로 매핑 -> 그 벡터를 output sequence로 decode하기 위하여 다른 deep LSTM 이용 

  * 더 자세한 정보 https://arxiv.org/abs/1409.3215

* training

  * 맞는 답(output sequence)의 cross entropy가 최대가 되도록

* inference

  * 예측된 output token을 다음 input으로 넣음 (greedy approach)
  * less greedy approach - beam search(몇 개의 가능한 후보를 넣음)

* 질문이 'ABC', 대답이 'WXYZ'

  ![Imgur](https://i.imgur.com/o1ENK3w.png)

* 한계

  *  최적화된 목적 함수가 실제 소통에서의 목적, 주제를 못잡아내는 경우가 있음
  * 대답의 일관성의 부족
  * 일반적인 지식의 부족

# 3. Datasets and Experiment
## 3.1. IT Helpdesk Troubleshooting experiments
* **Dataset**

   * IT 고객센터 상담 데이터셋
   * 보통 400단어 길이
   * 말하는 순서가 명시
   * 흔한 이름, 번호, URL제거하는 전처리
   * domain-specific

* **Experiment**

   * single layer LSTM(1024 memory cell)
   * SGD, gradient clipping

* **Perplexity**(테스트 문장이 생성될 확률이 높을수록 작은 값을 가짐)

   * n-gram model : 18
   * 우리 모델 : 8

* **Example**

   ![Imgur](https://i.imgur.com/Qkkeo2n.png)
## 3.2. OpenSubtitles experiments
* **Dataset**

   * 영화 자막에서 뽑은 대화
   * 말하는 순서 모름 - 한 문장씩 돌아가면서 말한다고 가정
   * 실제로 한 문장 두번씩 학습됨 (질문으로 한번, 대답으로 한번)
   * large, noisy data
   * open-domain

* **Experiment**

   * two-layered LSTM (4096 memory cells)
   * AdaGrad with gradient clipping

* **Perplexity**

   * smoothed 5-gram model : 28
   * 우리 모델 : 17
   * soft attention 효과 없었음

* **Example**

   ![Imgur](https://i.imgur.com/ijz0pWV.png)

   ![Imgur](https://i.imgur.com/MVhLAe8.png)

   ![Imgur](https://i.imgur.com/4jtkbsr.png)

* 복잡한 과정 없이도 모델이 사실을 기억하고 문맥을 이해하고 일반적인 수준의 추론을 할 수 있음

* 이미 존재하는 질문에 대한 답을 찾는 것이 아니라 , training set에 존재하지 않는 답을 했다는것  - 일반화 가능

* 단점

   * 간단하고 짧은 답은 잘함, 길고 복잡한 답은 잘못함

   * 비슷한 질문 했을 때 같은 답 잘못함

      ![Imgur](https://i.imgur.com/Mth2rz6.png)

      Nonetheless, one drawback of this basic model is that it

      only gives simple, short, sometimes unsatisfying answers
      to our questions as can be seen above. Perhaps a more problematic drawback is that the model does not capture
      a consistent personality. Indeed, if we ask not identical but
      semantically similar questions, the answers can sometimes
      be inconsistent. This is expected due to the simplicity of
      our model and the dataset in our experiments. The conversation
      below illustrates such failure:
# 4. Evaluation

* **Rule-based bot과 비교**
  * http://www.cleverbot.com/
* **Human Evaluation**
  * Neural Converation Model vs. Clever Bot
  * 사람이 두 대답 중 마음에 드는 것을 고르게 함
  * 200개중 97개는 NCM이 더 낫다, 60개는 CB가 낫다, 20개는 비슷하다, 23개는 판단 불가
  * ![Imgur](https://i.imgur.com/WJWa1mG.png)